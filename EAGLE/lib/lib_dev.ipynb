{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for EAGLE.lib modules development\n",
    "This notebook should be run from test environvent (not development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "from EAGLE.lib.seqs import load_fasta_to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conservative columns irregularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "CONS_THR = 0.98\n",
    "\n",
    "# input\n",
    "workdir = \"/media/denis/Data/Data/Bioinf/Projects/Reverse_ORFs/alignments/DnaK/\"\n",
    "dnaK_AORFs_aln_fasta = os.path.join(workdir, \"dnaK_AORFs_aln.fasta\")\n",
    "PF00208_aln_fasta = os.path.join(workdir, \"PF00208_seed_aln.fasta\")\n",
    "PF05088_aln_fasta = os.path.join(workdir, \"PF05088_seed_aln.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_irregularity(mult_aln_dict, cons_thr=CONS_THR, window_l=150, windows_step=75):  # This function will be the MultAln classmethod\n",
    "    # mult_aln_dict will be replaced with self.mult_aln_dict\n",
    "    windows_list = list()\n",
    "    i = 0\n",
    "    while i < (len(mult_aln_dict[mult_aln_dict.keys()[0]])):\n",
    "        windows_list.append(dict((seq_id, mult_aln_dict[seq_id][i: i+window_l]) for seq_id in mult_aln_dict))\n",
    "        i += windows_step\n",
    "    cons_cols_by_windows = numpy.array([cons_cols_num(w, cons_thr=cons_thr) for w in windows_list])\n",
    "    print(cons_cols_by_windows, cons_cols_by_windows.mean())\n",
    "    return chisquare(cons_cols_by_windows)\n",
    "\n",
    "\n",
    "def cons_cols_num(mult_aln_dict, cons_thr=CONS_THR):\n",
    "    cln = 0\n",
    "    for i in range(len(mult_aln_dict[mult_aln_dict.keys()[0]])):\n",
    "        s_num_dict = defaultdict(int)\n",
    "        for seq_id in mult_aln_dict:\n",
    "            s_num_dict[mult_aln_dict[seq_id][i].lower()] += 1\n",
    "        all_s_num = sum(s_num_dict.values())\n",
    "        if float(s_num_dict.get(\"-\", 0))/float(all_s_num) <= 1.0-cons_thr:\n",
    "            if float(sorted(s_num_dict.values(), reverse=True)[0])/float(all_s_num) >= cons_thr:\n",
    "                cln += 1\n",
    "    return cln\n",
    "\n",
    "\n",
    "def rarefy(mult_aln_dict, seqs_to_remain=100):\n",
    "    seqs_ids = mult_aln_dict.keys()\n",
    "    if len(seqs_ids) <= seqs_to_remain:\n",
    "        return mult_aln_dict\n",
    "    rarefyed_aln_dict = dict()\n",
    "    for i in range(seqs_to_remain):\n",
    "        seq_id = None\n",
    "        seq_id = seqs_ids.pop(numpy.random.randint(len(seqs_ids)))\n",
    "        rarefyed_aln_dict[seq_id] = mult_aln_dict[seq_id]\n",
    "    return rarefyed_aln_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 3, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]), 0.45714285714285713)\n",
      "Power_divergenceResult(statistic=45.25, pvalue=0.09401599631159645)\n",
      "(array([4, 2, 0, 0, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0]), 0.9333333333333333)\n",
      "Power_divergenceResult(statistic=24.57142857142857, pvalue=0.03904172878196133)\n",
      "(array([ 0,  0,  0,  0,  0,  1,  1,  0,  0,  1,  1,  0,  1,  2,  2,  1,  0,\n",
      "        0,  0,  0,  0,  1,  1,  1,  1,  0,  1,  1,  0,  3,  5,  3,  1,  0,\n",
      "        0,  3,  3,  6, 19, 27, 18,  8, 10, 18, 29, 19, 15, 20, 13,  6,  5,\n",
      "        7, 10, 15, 12,  8,  3,  2,  3,  2,  4,  5,  2,  0,  0,  1,  1,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0]), 4.128205128205129)\n",
      "Power_divergenceResult(statistic=824.260869565217, pvalue=1.555762467305417e-125)\n"
     ]
    }
   ],
   "source": [
    "dnaK_AORFs_aln_dict = rarefy(load_fasta_to_dict(dnaK_AORFs_aln_fasta))\n",
    "PF00208_aln_dict = load_fasta_to_dict(PF00208_aln_fasta)\n",
    "PF05088_aln_dict = load_fasta_to_dict(PF05088_aln_fasta)\n",
    "\n",
    "print(estimate_irregularity(mult_aln_dict=dnaK_AORFs_aln_dict, window_l=50, windows_step=25))  # 150; 75\n",
    "print(estimate_irregularity(mult_aln_dict=PF00208_aln_dict, window_l=50, windows_step=25))  # 60; 30\n",
    "print(estimate_irregularity(mult_aln_dict=PF05088_aln_dict, window_l=50, windows_step=25))  # 300; 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 100; alignment length 859\n",
      "Number of sequences: 97; alignment length 353\n",
      "Number of sequences: 113; alignment length 1934\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sequences: %s; alignment length %s\" % (len(dnaK_AORFs_aln_dict), len(dnaK_AORFs_aln_dict[dnaK_AORFs_aln_dict.keys()[0]])))\n",
    "print(\"Number of sequences: %s; alignment length %s\" % (len(PF00208_aln_dict), len(PF00208_aln_dict[PF00208_aln_dict.keys()[0]])))\n",
    "print(\"Number of sequences: %s; alignment length %s\" % (len(PF05088_aln_dict), len(PF05088_aln_dict[PF05088_aln_dict.keys()[0]])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
